import OpenAI from 'openai';

export interface OptimizationSuggestion {
  type: 'clarity' | 'specificity' | 'structure' | 'efficiency' | 'examples';
  title: string;
  description: string;
  originalText: string;
  suggestedText: string;
  confidence: number;
  impact: 'low' | 'medium' | 'high';
}

export interface PromptAnalysis {
  score: number;
  strengths: string[];
  weaknesses: string[];
  suggestions: OptimizationSuggestion[];
  estimatedTokens: number;
  readabilityScore: number;
}

class AIService {
  private openai: OpenAI | null = null;

  constructor() {
    console.log('ğŸ”§ AIService initializing...');
    console.log(`ğŸ”‘ OPENAI_API_KEY present: ${process.env.OPENAI_API_KEY ? 'YES' : 'NO'}`);
    
    if (process.env.OPENAI_API_KEY) {
      console.log(`ğŸ”‘ API Key length: ${process.env.OPENAI_API_KEY.length} characters`);
      this.openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });
      console.log('âœ… OpenAI client initialized successfully');
    } else {
      console.log('âš ï¸  No OpenAI API key found, using basic analysis mode');
    }
  }

  private isOpenAIEnabled(): boolean {
    return this.openai !== null;
  }

  async analyzePrompt(content: string): Promise<PromptAnalysis> {
    const basicAnalysis = this.getBasicAnalysis(content);

    if (!this.isOpenAIEnabled()) {
      return basicAnalysis;
    }

    try {
      const aiAnalysis = await this.getAIAnalysis(content);
      return {
        ...basicAnalysis,
        ...aiAnalysis,
      };
    } catch (error) {
      console.error('AI Analysis failed, falling back to basic analysis:', error);
      return basicAnalysis;
    }
  }

  private getBasicAnalysis(content: string): PromptAnalysis {
    const words = content.split(/\s+/).length;
    const estimatedTokens = Math.ceil(words * 1.3);
    const sentences = content.split(/[.!?]+/).filter(s => s.trim().length > 0).length;
    const avgWordsPerSentence = words / Math.max(sentences, 1);
    
    const readabilityScore = this.calculateReadabilityScore(content);
    const score = this.calculateBasicScore(content);

    const suggestions: OptimizationSuggestion[] = [];
    const strengths: string[] = [];
    const weaknesses: string[] = [];

    // Basic heuristic analysis
    if (content.length < 50) {
      weaknesses.push('æç¤ºè¯è¿‡äºç®€çŸ­ï¼Œå¯èƒ½ç¼ºä¹è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡');
      suggestions.push({
        type: 'specificity',
        title: 'å¢åŠ è¯¦ç»†ä¿¡æ¯',
        description: 'æç¤ºè¯å¤ªçŸ­ï¼Œå»ºè®®æ·»åŠ æ›´å¤šå…·ä½“è¦æ±‚å’Œä¸Šä¸‹æ–‡ä¿¡æ¯',
        originalText: content.substring(0, 100),
        suggestedText: 'è€ƒè™‘æ·»åŠ ï¼šå…·ä½“ä»»åŠ¡è¦æ±‚ã€æœŸæœ›è¾“å‡ºæ ¼å¼ã€ç¤ºä¾‹ç­‰',
        confidence: 0.8,
        impact: 'medium',
      });
    }

    if (content.length > 1000) {
      weaknesses.push('æç¤ºè¯è¿‡é•¿ï¼Œå¯èƒ½åŒ…å«å†—ä½™ä¿¡æ¯');
      suggestions.push({
        type: 'efficiency',
        title: 'ç®€åŒ–å†…å®¹',
        description: 'æç¤ºè¯è¿‡é•¿ï¼Œå»ºè®®å»é™¤å†—ä½™ä¿¡æ¯ï¼Œä¿ç•™æ ¸å¿ƒè¦æ±‚',
        originalText: content.substring(0, 100) + '...',
        suggestedText: 'ä¿ç•™æ ¸å¿ƒè¦æ±‚ï¼Œç§»é™¤é‡å¤æˆ–ä¸å¿…è¦çš„æè¿°',
        confidence: 0.7,
        impact: 'medium',
      });
    }

    if (avgWordsPerSentence > 25) {
      weaknesses.push('å¥å­è¿‡é•¿ï¼Œå½±å“ç†è§£');
      suggestions.push({
        type: 'clarity',
        title: 'ç®€åŒ–å¥å­ç»“æ„',
        description: 'å°†é•¿å¥æ‹†åˆ†ä¸ºå¤šä¸ªçŸ­å¥ï¼Œæé«˜å¯è¯»æ€§',
        originalText: 'é•¿å¥ç¤ºä¾‹...',
        suggestedText: 'æ‹†åˆ†ä¸ºå¤šä¸ªçŸ­å¥',
        confidence: 0.6,
        impact: 'low',
      });
    }

    if (!/[.!?]/.test(content)) {
      weaknesses.push('ç¼ºä¹æ ‡ç‚¹ç¬¦å·ï¼Œå½±å“ç»“æ„æ¸…æ™°åº¦');
    }

    if (content.includes('ä¾‹å¦‚') || content.includes('æ¯”å¦‚') || content.includes('ç¤ºä¾‹')) {
      strengths.push('åŒ…å«ç¤ºä¾‹è¯´æ˜ï¼Œæœ‰åŠ©äºç†è§£');
    }

    if (content.includes('è¯·') || content.includes('å¸®åŠ©') || content.includes('éœ€è¦')) {
      strengths.push('ä½¿ç”¨ç¤¼è²Œç”¨è¯­ï¼Œè¡¨è¾¾æ¸…æ™°');
    }

    return {
      score,
      strengths,
      weaknesses,
      suggestions,
      estimatedTokens,
      readabilityScore,
    };
  }

  private async getAIAnalysis(content: string): Promise<Partial<PromptAnalysis>> {
    if (!this.openai) return {};

    const prompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIæç¤ºè¯åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æç¤ºè¯çš„è´¨é‡å¹¶æä¾›è¯¦ç»†çš„æ”¹è¿›å»ºè®®ã€‚

å¾…åˆ†æçš„æç¤ºè¯ï¼š
'''
${content}
'''

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œä¸“ä¸šåˆ†æï¼š
1. **æ¸…æ™°åº¦** - æŒ‡ä»¤æ˜¯å¦æ˜ç¡®æ˜“æ‡‚
2. **å…·ä½“æ€§** - æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„å…·ä½“è¦æ±‚å’Œç»†èŠ‚
3. **ç»“æ„æ€§** - é€»è¾‘å±‚æ¬¡æ˜¯å¦æ¸…æ™°åˆç†
4. **å®Œæ•´æ€§** - æ˜¯å¦åŒ…å«å¿…è¦çš„ä¸Šä¸‹æ–‡å’Œçº¦æŸæ¡ä»¶
5. **æœ‰æ•ˆæ€§** - æ˜¯å¦èƒ½å¤Ÿäº§ç”ŸæœŸæœ›çš„è¾“å‡ºç»“æœ

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ˆåªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
  "score": è¯„åˆ†(0-100æ•´æ•°),
  "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
  "weaknesses": ["ç¼ºç‚¹1", "ç¼ºç‚¹2"],
  "suggestions": [
    {
      "type": "clarity|specificity|structure|efficiency|examples",
      "title": "å»ºè®®æ ‡é¢˜",
      "description": "è¯¦ç»†æè¿°",
      "suggestedText": "å…·ä½“æ”¹è¿›å»ºè®®",
      "confidence": 0.8,
      "impact": "low|medium|high"
    }
  ]
}`;

    try {
      const modelName = process.env.OPENAI_MODEL || 'gpt-4.1-nano';
      console.log(`ğŸ¤– Calling OpenAI API for analysis...`);
      console.log(`   ğŸ¯ Model: ${modelName}`);
      console.log(`   ğŸ“ Prompt length: ${prompt.length} characters`);
      
      const startTime = Date.now();
      const completion = await this.openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4.1-nano',
        messages: [{ role: 'user', content: prompt }],
        max_tokens: 1000,
        temperature: 0.3,
      });
      const apiDuration = Date.now() - startTime;
      
      console.log(`   âš¡ OpenAI API responded in ${apiDuration}ms`);
      console.log(`   ğŸ“Š Usage: ${completion.usage?.total_tokens || 'unknown'} tokens`);

      const response = completion.choices[0]?.message?.content;
      if (!response) return {};

      // Try to extract JSON from response
      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (!jsonMatch) return {};

      const analysis = JSON.parse(jsonMatch[0]);
      return analysis;
    } catch (error) {
      console.error('OpenAI API call failed:', error);
      return {};
    }
  }

  private calculateReadabilityScore(content: string): number {
    const words = content.split(/\s+/).length;
    const sentences = content.split(/[.!?]+/).filter(s => s.trim().length > 0).length;
    const avgWordsPerSentence = words / Math.max(sentences, 1);
    
    // Simple readability formula (lower is better, normalize to 0-100)
    const rawScore = avgWordsPerSentence * 2;
    return Math.max(0, Math.min(100, 100 - rawScore));
  }

  private calculateBasicScore(content: string): number {
    let score = 50; // Base score

    // Length scoring
    const length = content.length;
    if (length >= 100 && length <= 500) score += 20;
    else if (length >= 50 && length <= 800) score += 10;
    else if (length < 50) score -= 20;
    else if (length > 1000) score -= 10;

    // Structure scoring
    if (content.includes('è¯·') || content.includes('å¸®åŠ©')) score += 5;
    if (content.includes('ä¾‹å¦‚') || content.includes('ç¤ºä¾‹')) score += 10;
    if (/[.!?]/.test(content)) score += 5;
    if (content.includes('\n')) score += 5;

    return Math.max(0, Math.min(100, score));
  }

  async generateOptimizedVersion(
    originalContent: string,
    suggestions: OptimizationSuggestion[]
  ): Promise<string> {
    if (!this.isOpenAIEnabled()) {
      return this.applyBasicOptimizations(originalContent, suggestions);
    }

    try {
      const prompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIæç¤ºè¯ä¼˜åŒ–ä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„æ”¹è¿›å»ºè®®ä¼˜åŒ–ä»¥ä¸‹æç¤ºè¯ã€‚

åŸå§‹æç¤ºè¯ï¼š
'''
${originalContent}
'''

ä¼˜åŒ–å»ºè®®ï¼š
${suggestions.map(s => `â€¢ ${s.title}: ${s.description}`).join('\n')}

è¯·è¿”å›ä¼˜åŒ–åçš„æç¤ºè¯ï¼Œè¦æ±‚ï¼š
1. ä¿æŒåŸå§‹æ„å›¾å’Œæ ¸å¿ƒè¦æ±‚ä¸å˜
2. åº”ç”¨æ‰€æœ‰å¯è¡Œçš„æ”¹è¿›å»ºè®®
3. ç¡®ä¿è¯­è¨€æ›´åŠ æ¸…æ™°ã€å…·ä½“ã€æœ‰æ¡ç†
4. åªè¿”å›ä¼˜åŒ–åçš„æç¤ºè¯å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Š

ä¼˜åŒ–åçš„æç¤ºè¯ï¼š`;

      const completion = await this.openai!.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4.1-nano',
        messages: [{ role: 'user', content: prompt }],
        max_tokens: 800,
        temperature: 0.5,
      });

      return completion.choices[0]?.message?.content || originalContent;
    } catch (error) {
      console.error('Optimization generation failed:', error);
      return this.applyBasicOptimizations(originalContent, suggestions);
    }
  }

  private applyBasicOptimizations(
    originalContent: string,
    suggestions: OptimizationSuggestion[]
  ): string {
    let optimized = originalContent;

    // Apply basic text improvements
    for (const suggestion of suggestions) {
      if (suggestion.type === 'clarity' && suggestion.confidence > 0.7) {
        // Add punctuation if missing
        if (!optimized.endsWith('.') && !optimized.endsWith('!') && !optimized.endsWith('?')) {
          optimized += 'ã€‚';
        }
      }
    }

    return optimized;
  }

  async getSimilarPrompts(content: string, limit: number = 5): Promise<string[]> {
    // In a real implementation, this would search through a database of prompts
    // For now, return mock similar prompts
    const mockSimilarPrompts = [
      'åˆ›å»ºä¸€ä¸ªå“åº”å¼ç½‘é¡µè®¾è®¡',
      'ç”Ÿæˆç°ä»£åŒ–çš„ç”¨æˆ·ç•Œé¢',
      'å¼€å‘ç§»åŠ¨ç«¯å‹å¥½çš„é¡µé¢',
      'è®¾è®¡ç®€æ´çš„äº§å“å±•ç¤ºé¡µ',
      'æ„å»ºäº¤äº’å¼çš„ç”¨æˆ·ä½“éªŒ',
    ];

    return mockSimilarPrompts.slice(0, limit);
  }

  async categorizePrompt(content: string): Promise<string[]> {
    if (!this.isOpenAIEnabled()) {
      return this.getBasicCategories(content);
    }

    try {
      const prompt = `è¯·ä¸ºä»¥ä¸‹AIæç¤ºè¯åˆ†ç±»ï¼Œä»ä¸‹åˆ—ç±»åˆ«ä¸­é€‰æ‹©æœ€åˆé€‚çš„1-3ä¸ªç±»åˆ«ï¼š

æç¤ºè¯å†…å®¹ï¼š
'''
${content}
'''

å¯é€‰ç±»åˆ«ï¼š
- web-development (ç½‘é¡µå¼€å‘)
- design (è®¾è®¡ç›¸å…³)
- programming (ç¼–ç¨‹å¼€å‘)
- documentation (æ–‡æ¡£å†™ä½œ)
- testing (æµ‹è¯•è°ƒè¯•)
- content-creation (å†…å®¹åˆ›ä½œ)
- data-analysis (æ•°æ®åˆ†æ)
- general (é€šç”¨)

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›åˆ†ç±»ç»“æœï¼Œä¾‹å¦‚ï¼š["web-development", "design"]`;

      const completion = await this.openai!.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4.1-nano',
        messages: [{ role: 'user', content: prompt }],
        max_tokens: 100,
        temperature: 0.1,
      });

      const response = completion.choices[0]?.message?.content;
      if (response) {
        const categories = JSON.parse(response.trim());
        return Array.isArray(categories) ? categories : ['general'];
      }
    } catch (error) {
      console.error('AI categorization failed:', error);
    }

    return this.getBasicCategories(content);
  }

  private getBasicCategories(content: string): string[] {
    const categories: string[] = [];
    const lowerContent = content.toLowerCase();

    if (lowerContent.includes('ç½‘é¡µ') || lowerContent.includes('ç½‘ç«™') || lowerContent.includes('html')) {
      categories.push('web-development');
    }
    if (lowerContent.includes('è®¾è®¡') || lowerContent.includes('ui') || lowerContent.includes('ç•Œé¢')) {
      categories.push('design');
    }
    if (lowerContent.includes('ä»£ç ') || lowerContent.includes('ç¼–ç¨‹') || lowerContent.includes('å¼€å‘')) {
      categories.push('programming');
    }
    if (lowerContent.includes('æ–‡æ¡£') || lowerContent.includes('è¯´æ˜') || lowerContent.includes('æ•™ç¨‹')) {
      categories.push('documentation');
    }
    if (lowerContent.includes('æµ‹è¯•') || lowerContent.includes('è°ƒè¯•')) {
      categories.push('testing');
    }

    return categories.length > 0 ? categories : ['general'];
  }

  async validatePrompt(content: string): Promise<{
    isValid: boolean;
    score: number;
    issues: string[];
    suggestions: string[];
  }> {
    if (!this.isOpenAIEnabled()) {
      return {
        isValid: content.length > 10,
        score: this.calculateBasicScore(content),
        issues: content.length <= 10 ? ['æç¤ºè¯è¿‡çŸ­'] : [],
        suggestions: ['å»ºè®®æ·»åŠ æ›´å¤šå…·ä½“è¦æ±‚']
      };
    }

    try {
      const prompt = `ä½ æ˜¯ä¸€ä¸ªAIæç¤ºè¯éªŒè¯ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹æç¤ºè¯çš„æœ‰æ•ˆæ€§ï¼š

æç¤ºè¯ï¼š
'''
${content}
'''

è¯„ä¼°æ ‡å‡†ï¼š
1. æ˜¯å¦æ¸…æ™°æ˜ç¡®
2. æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯
3. æ˜¯å¦å¯ä»¥äº§ç”Ÿæœ‰ç”¨çš„è¾“å‡º
4. æ˜¯å¦å­˜åœ¨æ­§ä¹‰æˆ–çŸ›ç›¾

è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼š
{
  "isValid": true/false,
  "score": 0-100,
  "issues": ["é—®é¢˜1", "é—®é¢˜2"],
  "suggestions": ["å»ºè®®1", "å»ºè®®2"]
}`;

      const completion = await this.openai!.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4.1-nano',
        messages: [{ role: 'user', content: prompt }],
        max_tokens: 500,
        temperature: 0.2,
      });

      const response = completion.choices[0]?.message?.content;
      if (response) {
        const result = JSON.parse(response.trim());
        return {
          isValid: result.isValid || false,
          score: result.score || 0,
          issues: result.issues || [],
          suggestions: result.suggestions || []
        };
      }
    } catch (error) {
      console.error('Prompt validation failed:', error);
    }

    // Fallback to basic validation
    return {
      isValid: content.length > 10,
      score: this.calculateBasicScore(content),
      issues: content.length <= 10 ? ['æç¤ºè¯è¿‡çŸ­'] : [],
      suggestions: ['å»ºè®®æ·»åŠ æ›´å¤šå…·ä½“è¦æ±‚']
    };
  }
}

// å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç¡®ä¿ç¯å¢ƒå˜é‡å·²åŠ è½½
let aiServiceInstance: AIService | null = null;

export const getAIService = (): AIService => {
  if (!aiServiceInstance) {
    aiServiceInstance = new AIService();
  }
  return aiServiceInstance;
};

// ä¿æŒå‘åå…¼å®¹
export const aiService = getAIService();